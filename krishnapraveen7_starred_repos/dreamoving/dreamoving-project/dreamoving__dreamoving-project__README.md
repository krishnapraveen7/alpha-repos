# [dreamoving-project](https://github.com/dreamoving/dreamoving-project)

# DreaMoving

[![Paper](https://img.shields.io/badge/cs.CV-Paper-b31b1b?logo=arxiv&logoColor=red)](https://arxiv.org/abs/2312.05107)
[![Project Page](https://img.shields.io/badge/DreaMoving-Website-green?logo=googlechrome&logoColor=green)](https://dreamoving.github.io/dreamoving)
[![Video](https://img.shields.io/badge/YouTube-Video-c4302b?logo=youtube&logoColor=red)](https://github.com/dreamoving/dreamoving-project)

> **DreaMoving: A Human Video Generation Framework based on Diffusion Models**<br>
> [Mengyang Feng](https://github.com/ArcherFMY), [Jinlin Liu](), [Kai Yu](), [Yuan Yao](), [Zheng Hui](), [Xiefan Guo](), [Xianhui Lin](), [Haolan Xue](), [Chen Shi](), [Xiaowen Li](), [Aojie Li](), [Xiaoyang Kang](), [Biwen Lei](), [Miaomiao Cui](), [Peiran Ren](), [Xuansong Xie]()<br>
> Institute for Intelligent Computing, Alibaba Group

<strong>TL;DR</strong>: <strong>DreaMoving</strong> is a diffusion-based controllable video generation framework to produce high-quality customized human videos.

## Demo
中文版
[ModelScope创空间](https://www.modelscope.cn/studios/vigen/video_generation/summary)

English Version [HuggingFace](https://huggingface.co/spaces/jiayong/Dreamoving)

<table border="0" cellspacing="0" cellpadding="0" align="center">
    <tr>
        <td align="center" valign="middle">
            <img src="assets/videos/teaser/1.gif">
        </td>
        <td align="center" valign="middle">
            <img src="assets/videos/teaser/2.gif">
        </td>
        <td align="center" valign="middle">
            <img src="assets/videos/teaser/3.gif">
        </td>
        <td align="center" valign="middle">
            <img src="assets/videos/teaser/4.gif">
        </td>
        <td align="center" valign="middle">
            <img src="assets/videos/teaser/5.gif">
        </td>
        <td align="center" valign="middle">
            <img src="assets/videos/teaser/6.gif">
        </td>
    </tr>
    <tr>
        <td align="center" valign="middle" width="16%">
            <p style="font-size: 14px;" align="center">
                A girl, smiling, standing on a beach next to the ocean, wearing light yellow dress with long sleeves.
            </p>
        </td>
        <td align="center" valign="middle" width="16%">
            <p style="font-size: 14px;" align="center">
                An Asian girl, smiling, dancing in central park, wearing long shirt and long jeans.
            </p>
        </td>
        <td align="center" valign="middle" width="16%">
            <p style="font-size: 14px;" align="center">
                A girl, smiling, in the park with golden leaves in autumn wearing coat with long sleeve.
            </p>
        </td>
        <td align="center" valign="middle" width="16%">
            <p style="font-size: 14px;" align="center">
                A man, dancing in front of Pyramids of Egypt, wearing a suit with a blue tie.
            </p>
        </td>
        <td align="center" valign="middle" width="16%">
            <p style="font-size: 14px;" align="center">
                A girl, smiling, dancing in a French town, wearing long light blue dress.
            </p>
        </td>
        <td align="center" valign="middle" width="16%">
            <p style="font-size: 14px;" align="center">
                A woman, smiling, in Times Square, wearing white clothes and long pants.
            </p>
        </td>
    </tr>
</table>

## Citation

```bibtex
@article{feng2023dreamoving,
    title={DreaMoving: A Human Video Generation Framework based on Diffusion Models},
    author={Mengyang Feng, Jinlin Liu, Kai Yu, Yuan Yao, Zheng Hui, Xiefan Guo, Xianhui Lin, Haolan Xue,
            Chen Shi, Xiaowen Li, Aojie Li, Xiaoyang Kang, Biwen Lei, Miaomiao Cui, Peiran Ren, Xuansong Xie},
    journal={arXiv},
    year={2023}
}
```
